{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for NB Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "#!pip install xgboost\n",
    "#!brew install libomp\n",
    "# import kaggle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "# Learning libs\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, make_scorer\n",
    "f1 = make_scorer(f1_score , average='macro')\n",
    "\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Producing Decision Tree diagrams\n",
    "from IPython.display import Image, display\n",
    "import pydotplus\n",
    "from subprocess import call\n",
    "\n",
    "# For other \n",
    "import copy\n",
    "from textwrap import wrap\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/processed/train_data.csv').set_index('Id')\n",
    "train_labels = pd.read_csv('../data/processed/train_labels.csv').set_index('Id')\n",
    "dev_data = pd.read_csv('../data/processed/dev_data.csv').set_index('Id')\n",
    "dev_labels = pd.read_csv('../data/processed/dev_labels.csv').set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.merge(train_labels, how = 'left', on = train_data.index)\\\n",
    "        .set_index(train_data.index)\\\n",
    "        .drop(['key_0'], axis = 1)\n",
    "\n",
    "dev = dev_data.merge(dev_labels, how = 'left', on = dev_data.index)\\\n",
    "        .set_index(dev_data.index)\\\n",
    "        .drop(['key_0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_data and Dev_data: for models, does not include labels in DF\n",
      "(12096, 54)\n",
      "(3024, 54)\n",
      "(12096, 1)\n",
      "(3024, 1)\n",
      "\n",
      "Train and Dev: for EDA, includes labels in DF for easy plotting\n",
      "(12096, 55)\n",
      "(3024, 55)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train_data and Dev_data: for models, does not include labels in DF\")\n",
    "print(train_data.shape)\n",
    "print(dev_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(dev_labels.shape)\n",
    "\n",
    "print(\"\\nTrain and Dev: for EDA, includes labels in DF for easy plotting\")\n",
    "print(train.shape)\n",
    "print(dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zeros</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>0</td>\n",
       "      <td>12096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>91</td>\n",
       "      <td>12096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>4</td>\n",
       "      <td>12096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>1267</td>\n",
       "      <td>12096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>1500</td>\n",
       "      <td>12096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  zeros  total\n",
       "Elevation                             0  12096\n",
       "Aspect                               91  12096\n",
       "Slope                                 4  12096\n",
       "Horizontal_Distance_To_Hydrology   1267  12096\n",
       "Vertical_Distance_To_Hydrology     1500  12096"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zero values \n",
    "# ------------------------------------------------------------------------------\n",
    "zero_counts = pd.DataFrame({'zeros':train_data[train_data == 0].count(), 'total':train_data.count()})\n",
    "\n",
    "zero_features = zero_counts[zero_counts.zeros == zero_counts.total].index.to_list()\n",
    "zero_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns = zero_features, inplace = True)\n",
    "dev_data.drop(columns = zero_features, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12400</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>215.564376</td>\n",
       "      <td>192</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5954</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total_Distance_To_Hydrology  Horizontal_Distance_To_Hydrology  \\\n",
       "Id                                                                     \n",
       "4429                      0.000000                                 0   \n",
       "12400                     0.000000                                 0   \n",
       "4648                    215.564376                               192   \n",
       "5954                      0.000000                                 0   \n",
       "2947                      0.000000                                 0   \n",
       "\n",
       "       Vertical_Distance_To_Hydrology  \n",
       "Id                                     \n",
       "4429                                0  \n",
       "12400                               0  \n",
       "4648                               98  \n",
       "5954                                0  \n",
       "2947                                0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total_Distance_to_Hydrology\n",
    "# ------------------------------------------------------------------------------\n",
    "# Create Total_Distance_to_Hydrology based on Euclidean distance\n",
    "train_data['Total_Distance_To_Hydrology'] = np.sqrt(train_data[\"Horizontal_Distance_To_Hydrology\"]**2 + train_data['Vertical_Distance_To_Hydrology']**2)\n",
    "dev_data['Total_Distance_To_Hydrology'] = np.sqrt(dev_data[\"Horizontal_Distance_To_Hydrology\"]**2 + dev_data['Vertical_Distance_To_Hydrology']**2)\n",
    "train_data[[\"Total_Distance_To_Hydrology\", \"Horizontal_Distance_To_Hydrology\", \"Vertical_Distance_To_Hydrology\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
      "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
      "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
      "       'Horizontal_Distance_To_Fire_Points', 'Total_Distance_To_Hydrology'],\n",
      "      dtype='object')\n",
      "Index(['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n",
      "       'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n",
      "       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type9', 'Soil_Type10',\n",
      "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
      "       'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19',\n",
      "       'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23',\n",
      "       'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27',\n",
      "       'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31',\n",
      "       'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35',\n",
      "       'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39',\n",
      "       'Soil_Type40'],\n",
      "      dtype='object')\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 51]\n"
     ]
    }
   ],
   "source": [
    "continuous_features = list(train_data.columns[0:10]) + ['Total_Distance_To_Hydrology']\n",
    "binary_features = train_data.columns[10:-1].to_list()\n",
    "\n",
    "continuous_index = [train_data.columns.tolist().index(f) for f in continuous_features]\n",
    "binary_index = [train_data.columns.tolist().index(f) for f in binary_features]\n",
    "\n",
    "print(train_data.iloc[:,continuous_index].columns)\n",
    "print(train_data.iloc[:,binary_index].columns)\n",
    "print(continuous_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>Total_Distance_To_Hydrology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.209600e+04</td>\n",
       "      <td>1.209600e+04</td>\n",
       "      <td>1.209600e+04</td>\n",
       "      <td>1.209600e+04</td>\n",
       "      <td>1.209600e+04</td>\n",
       "      <td>1.209600e+04</td>\n",
       "      <td>1.209600e+04</td>\n",
       "      <td>1.209600e+04</td>\n",
       "      <td>1.209600e+04</td>\n",
       "      <td>1.209600e+04</td>\n",
       "      <td>1.209600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.946827e-16</td>\n",
       "      <td>-3.465776e-17</td>\n",
       "      <td>1.373552e-16</td>\n",
       "      <td>-1.859917e-16</td>\n",
       "      <td>-5.837482e-18</td>\n",
       "      <td>-1.061531e-16</td>\n",
       "      <td>2.473817e-16</td>\n",
       "      <td>2.816367e-16</td>\n",
       "      <td>1.872538e-16</td>\n",
       "      <td>5.739617e-17</td>\n",
       "      <td>-1.657625e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.124240e+00</td>\n",
       "      <td>-1.423808e+00</td>\n",
       "      <td>-1.955819e+00</td>\n",
       "      <td>-1.083077e+00</td>\n",
       "      <td>-3.209591e+00</td>\n",
       "      <td>-1.298828e+00</td>\n",
       "      <td>-6.906541e+00</td>\n",
       "      <td>-5.260928e+00</td>\n",
       "      <td>-2.949754e+00</td>\n",
       "      <td>-1.380555e+00</td>\n",
       "      <td>-1.096632e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.952984e-01</td>\n",
       "      <td>-8.337014e-01</td>\n",
       "      <td>-7.719155e-01</td>\n",
       "      <td>-7.639456e-01</td>\n",
       "      <td>-7.497377e-01</td>\n",
       "      <td>-7.188853e-01</td>\n",
       "      <td>-5.362354e-01</td>\n",
       "      <td>-5.247223e-01</td>\n",
       "      <td>-6.176491e-01</td>\n",
       "      <td>-7.119251e-01</td>\n",
       "      <td>-7.838265e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.446341e-03</td>\n",
       "      <td>-2.799089e-01</td>\n",
       "      <td>-1.799639e-01</td>\n",
       "      <td>-2.257094e-01</td>\n",
       "      <td>-3.098964e-01</td>\n",
       "      <td>-3.022646e-01</td>\n",
       "      <td>2.438020e-01</td>\n",
       "      <td>1.769377e-01</td>\n",
       "      <td>5.800748e-02</td>\n",
       "      <td>-2.344632e-01</td>\n",
       "      <td>-2.249585e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.463011e-01</td>\n",
       "      <td>9.456974e-01</td>\n",
       "      <td>6.487684e-01</td>\n",
       "      <td>4.887633e-01</td>\n",
       "      <td>4.720437e-01</td>\n",
       "      <td>4.205838e-01</td>\n",
       "      <td>7.313254e-01</td>\n",
       "      <td>7.031828e-01</td>\n",
       "      <td>7.118686e-01</td>\n",
       "      <td>4.371392e-01</td>\n",
       "      <td>4.928629e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.633417e+00</td>\n",
       "      <td>1.844475e+00</td>\n",
       "      <td>4.200478e+00</td>\n",
       "      <td>5.313836e+00</td>\n",
       "      <td>8.193702e+00</td>\n",
       "      <td>3.910823e+00</td>\n",
       "      <td>1.348855e+00</td>\n",
       "      <td>1.536404e+00</td>\n",
       "      <td>2.455498e+00</td>\n",
       "      <td>4.887734e+00</td>\n",
       "      <td>5.204268e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Elevation        Aspect         Slope  \\\n",
       "count  1.209600e+04  1.209600e+04  1.209600e+04   \n",
       "mean   2.946827e-16 -3.465776e-17  1.373552e-16   \n",
       "std    1.000041e+00  1.000041e+00  1.000041e+00   \n",
       "min   -2.124240e+00 -1.423808e+00 -1.955819e+00   \n",
       "25%   -8.952984e-01 -8.337014e-01 -7.719155e-01   \n",
       "50%    5.446341e-03 -2.799089e-01 -1.799639e-01   \n",
       "75%    8.463011e-01  9.456974e-01  6.487684e-01   \n",
       "max    2.633417e+00  1.844475e+00  4.200478e+00   \n",
       "\n",
       "       Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  \\\n",
       "count                      1.209600e+04                    1.209600e+04   \n",
       "mean                      -1.859917e-16                   -5.837482e-18   \n",
       "std                        1.000041e+00                    1.000041e+00   \n",
       "min                       -1.083077e+00                   -3.209591e+00   \n",
       "25%                       -7.639456e-01                   -7.497377e-01   \n",
       "50%                       -2.257094e-01                   -3.098964e-01   \n",
       "75%                        4.887633e-01                    4.720437e-01   \n",
       "max                        5.313836e+00                    8.193702e+00   \n",
       "\n",
       "       Horizontal_Distance_To_Roadways  Hillshade_9am  Hillshade_Noon  \\\n",
       "count                     1.209600e+04   1.209600e+04    1.209600e+04   \n",
       "mean                     -1.061531e-16   2.473817e-16    2.816367e-16   \n",
       "std                       1.000041e+00   1.000041e+00    1.000041e+00   \n",
       "min                      -1.298828e+00  -6.906541e+00   -5.260928e+00   \n",
       "25%                      -7.188853e-01  -5.362354e-01   -5.247223e-01   \n",
       "50%                      -3.022646e-01   2.438020e-01    1.769377e-01   \n",
       "75%                       4.205838e-01   7.313254e-01    7.031828e-01   \n",
       "max                       3.910823e+00   1.348855e+00    1.536404e+00   \n",
       "\n",
       "       Hillshade_3pm  Horizontal_Distance_To_Fire_Points  \\\n",
       "count   1.209600e+04                        1.209600e+04   \n",
       "mean    1.872538e-16                        5.739617e-17   \n",
       "std     1.000041e+00                        1.000041e+00   \n",
       "min    -2.949754e+00                       -1.380555e+00   \n",
       "25%    -6.176491e-01                       -7.119251e-01   \n",
       "50%     5.800748e-02                       -2.344632e-01   \n",
       "75%     7.118686e-01                        4.371392e-01   \n",
       "max     2.455498e+00                        4.887734e+00   \n",
       "\n",
       "       Total_Distance_To_Hydrology  \n",
       "count                 1.209600e+04  \n",
       "mean                 -1.657625e-16  \n",
       "std                   1.000041e+00  \n",
       "min                  -1.096632e+00  \n",
       "25%                  -7.838265e-01  \n",
       "50%                  -2.249585e-01  \n",
       "75%                   4.928629e-01  \n",
       "max                   5.204268e+00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform continuous features to normalize\n",
    "X_train = train_data[continuous_features + binary_features]\n",
    "X_dev = dev_data[continuous_features + binary_features]\n",
    "X_train.shape\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "        ('features', StandardScaler(), continuous_features)\n",
    "        ], remainder='passthrough')\n",
    "nX_train = ct.fit_transform(X_train)\n",
    "nX_dev = ct.transform(X_dev)\n",
    "pd.DataFrame(nX_train, columns = X_train.columns).loc[:,continuous_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12096, 52)\n",
      "(12096, 52)\n",
      "(3024, 52)\n",
      "(3024, 52)\n"
     ]
    }
   ],
   "source": [
    "# Relabel outcome variable - check match\n",
    "y_train = train_labels.Cover_Type\n",
    "y_dev = dev_labels.Cover_Type\n",
    "\n",
    "print(X_train.shape)\n",
    "print(nX_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(nX_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Strategy and Results\n",
    "\n",
    "Our first attempt for modeling this problem involved using the Naive Bayes classifier. Based on the course content and additional research that we had done, we believed that while Naive Bayes tends to be overconfident about results, the classifier tends to generalize well to different data sets.\n",
    "\n",
    "We realized quickly, however, that our set of data includes both binary and continuous variables, which makes it more difficult to produce a Naive Bayes model. A Gaussian Naive Bayes model requires the use of continuous data, and a Bernoulli Naive Bayes model requires the data to be binary (or ordered, in the case of using a Multinomial model). There is not one model that utilizes both continuous and binary data.\n",
    "\n",
    "One option we had was to convert the continuous data into binary or multinomial data, which would result in a loss of information, but may simplify the model so that it generalizes better. Another option we looked into was combining the results of a Bernoulli model with the results of a Gaussian model. Other attempts at improving our F1 Score and accuracy included smoothing the model, transforming our continuous features using the Yeo-Johnson method, and removing subsets of features. After extensive model tuning, we found that we could only reach a maximum F1 score of **63.9%** and an accuracy of **63.7%** using the Naive Bayes Classifier. While this in part could be due to having two classes of data, we believe that this data set also violates the independence assumption required for a Naive Bayes model, in which features are assumed to be independent. Based on our scatterplots above, it may be the case that our features are too closely related. \n",
    "\n",
    "A summary of our modeling iterations is presented in this section below, but a more detailed description of our results can be found in the Appendix at the end of this document.\n",
    "\n",
    "\n",
    "**[INSERT RESULTS BELOW - MODEL TYPES AND SCORES]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [All that follows below will be in our Appendix]\n",
    "\n",
    "Our features are represented by two different classes of data. We have **continuous variables** (elevation, aspect, slope, horizontal/vertical distance to hydrology, horizontal distance to roadways, hillshade, horizontal distance to fire points), and **binary variables** (wilderness areas, soil types), all of which are associated with 7 different tree cover types.\n",
    "\n",
    "Because there is a mix of continuous/binary variables, we cannot just use a Gaussian (continuous) or Bernoulli (binary) Naive Bayes.\n",
    "\n",
    "As a first pass, we train and evaluate models on the subsets of features that immediately fit into the models.\n",
    "\n",
    "Later, feature selection, transformation, etc. will be performed to allow for combinations of such features into a single Naive Bayes Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Gaussian Naive Bayes with strictly continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NB, we will remove 'Total_Distance_to_Hydrology'\n",
    "continuous_features.remove('Total_Distance_To_Hydrology') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes (Only Continuous Features)\n",
      "F1: 0.583 \n",
      "Accuracy: 0.592\n"
     ]
    }
   ],
   "source": [
    "# Fit Gaussian Naive Bayes\n",
    "gausNB = GaussianNB().fit(X_train[continuous_features], np.array(y_train).ravel())          # Fit\n",
    "gausNB_pred = gausNB.predict(X_dev[continuous_features])                  # Predict\n",
    "\n",
    "gausNB_f1 = metrics.f1_score(y_dev, gausNB_pred, average = 'weighted')    # F1\n",
    "gausNB_accur = gausNB.score(X_dev[continuous_features], y_dev)            # Accuracy\n",
    "\n",
    "print('Gaussian Naive Bayes (Only Continuous Features)')\n",
    "print(f'F1: {gausNB_f1:.3f} \\nAccuracy: {gausNB_accur:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Bernoulli Naive Bayes with strictly binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes (Only Binary features)\n",
      "F1: 0.578 \n",
      "Accuracy: 0.583\n"
     ]
    }
   ],
   "source": [
    "# Fit Bernoulli Naive Bayes\n",
    "bNB = BernoulliNB().fit(X_train[binary_features], np.array(y_train).ravel())          # Fit\n",
    "bNB_pred = bNB.predict(X_dev[binary_features])                      # Predict\n",
    "\n",
    "bNB_f1 = metrics.f1_score(y_dev, bNB_pred, average = 'weighted')    # F1\n",
    "bNB_accur = bNB.score(X_dev[binary_features], y_dev)                # Accuracy\n",
    "\n",
    "print('Bernoulli Naive Bayes (Only Binary features)')\n",
    "print(f'F1: {bNB_f1:.3f} \\nAccuracy: {bNB_accur:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the results of a Bernoulli Model and a Gaussian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Gaussian and Bernoulli Probability Model\n",
      "F1: 0.311 \n",
      "Accuracy: 0.356\n"
     ]
    }
   ],
   "source": [
    "# Get probability predictions for each model\n",
    "# On training data\n",
    "G_train_probs = gausNB.predict_proba(X_train[continuous_features])\n",
    "C_train_probs = bNB.predict_proba(X_train[binary_features])\n",
    "\n",
    "# On dev data\n",
    "G_dev_probs = gausNB.predict_proba(X_dev[continuous_features])\n",
    "C_dev_probs = bNB.predict_proba(X_dev[binary_features])\n",
    "\n",
    "# Combine probability prediction for class=1 from both models into a 2D array\n",
    "# np.c_ translates slice objects to concatenation along the second axis.\n",
    "X_new_train = np.c_[(G_train_probs[:,1], C_train_probs[:,1])] # Train\n",
    "X_new_dev = np.c_[(G_dev_probs[:,1], C_dev_probs[:,1])] # Dev\n",
    "\n",
    "# Fit final Gaussian model\n",
    "# Using the probabilities from the last two modes as input\n",
    "model = GaussianNB().fit(X_new_train, y_train)\n",
    "\n",
    "# Predict class labels on dev data\n",
    "pred_labels_dev = model.predict(X_new_dev)\n",
    "\n",
    "combined_f1 = metrics.f1_score(y_dev, pred_labels_dev, average = 'weighted') \n",
    "combined_score = model.score(X_new_dev, y_dev)\n",
    "\n",
    "print('Combined Gaussian and Bernoulli Probability Model')\n",
    "print(f'F1: {combined_f1:.3f} \\nAccuracy: {combined_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined model does extremely worse, with an F1 score of 0.311 and an accuracy of 0.356. This is unacceptable for a predictive model, so we will move away from this method. Next, we will attempt to binarize the continuous variables to input into a Bernoulli model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarize Continuous Features\n",
    "\n",
    "Even despite the combined model's unacceptable accuracy, we can still see that separately, the Gaussian model and the Bernoulli model does a poor job of prediction, each under 60% accuracy. Let's try to binarize some of the continuous variables across their means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean of each continuous column and append to list\n",
    "mean_list = []\n",
    "for feature in continuous_features:\n",
    "    mean_list.append(np.mean(X_train[feature]))\n",
    "\n",
    "# Define function to binarize on the mean (referenced Week 2 Tutorial)\n",
    "def binarize_data(data, feature_cols, thresholds = mean_list):\n",
    "    '''\n",
    "    Purpose: binarize continuous features, where 0 represents below (or equal to) mean, 1 represents above mean\n",
    "    Input: continuous feature columns, names of features to be binarized, thresholds for binarization\n",
    "    Output: binarized feature columns, same shape of input\n",
    "    '''\n",
    "    \n",
    "    # Initialize a new feature array with the same shape as the original data.\n",
    "    binarized_data = data.copy() # avoid changing the original data\n",
    "\n",
    "    # Apply a threshold  to each feature.\n",
    "    i = 0\n",
    "    for feature in feature_cols:\n",
    "        binarized_data[feature] = 1 * (binarized_data[feature] > thresholds[i])\n",
    "        i+=1\n",
    "    return binarized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test a Bernoulli NB model with Binarized + Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes (All features binarized + Binary features)\n",
      "F1: 0.610 \n",
      "Accuracy: 0.617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Wilderness_Area1',\n",
       " 'Wilderness_Area2',\n",
       " 'Wilderness_Area3',\n",
       " 'Wilderness_Area4',\n",
       " 'Soil_Type1',\n",
       " 'Soil_Type2',\n",
       " 'Soil_Type3',\n",
       " 'Soil_Type4',\n",
       " 'Soil_Type5',\n",
       " 'Soil_Type6',\n",
       " 'Soil_Type9',\n",
       " 'Soil_Type10',\n",
       " 'Soil_Type11',\n",
       " 'Soil_Type12',\n",
       " 'Soil_Type13',\n",
       " 'Soil_Type14',\n",
       " 'Soil_Type16',\n",
       " 'Soil_Type17',\n",
       " 'Soil_Type18',\n",
       " 'Soil_Type19',\n",
       " 'Soil_Type20',\n",
       " 'Soil_Type21',\n",
       " 'Soil_Type22',\n",
       " 'Soil_Type23',\n",
       " 'Soil_Type24',\n",
       " 'Soil_Type25',\n",
       " 'Soil_Type26',\n",
       " 'Soil_Type27',\n",
       " 'Soil_Type28',\n",
       " 'Soil_Type29',\n",
       " 'Soil_Type30',\n",
       " 'Soil_Type31',\n",
       " 'Soil_Type32',\n",
       " 'Soil_Type33',\n",
       " 'Soil_Type34',\n",
       " 'Soil_Type35',\n",
       " 'Soil_Type36',\n",
       " 'Soil_Type37',\n",
       " 'Soil_Type38',\n",
       " 'Soil_Type39',\n",
       " 'Soil_Type40']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the continuous variables to binary\n",
    "bin_train_X = binarize_data(X_train, continuous_features) # Binarize all continuous features\n",
    "bin_dev_X = binarize_data(X_dev, continuous_features)\n",
    "\n",
    "# Fit Bernoulli Naive Bayes\n",
    "bNB2 = BernoulliNB().fit(bin_train_X, np.array(y_train).ravel())     # Fit\n",
    "bNB_pred2 = bNB2.predict(bin_dev_X)                                  # Predict\n",
    "\n",
    "bNB_f1 = metrics.f1_score(y_dev, bNB_pred2, average = 'weighted')    # F1\n",
    "bNB_accur = bNB2.score(bin_dev_X, y_dev)                             # Accuracy\n",
    "\n",
    "print('Bernoulli Naive Bayes (All features binarized + Binary features)')\n",
    "print(f'F1: {bNB_f1:.3f} \\nAccuracy: {bNB_accur:.3f}')\n",
    "binary_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there are only marginal returns to accuracy after adding in binarized features. This could be for a number of reasons, but is most likely due to the distribution of each continuous variable. When we split on mean, we are making some assumption that this is a \"good\" split, which mostly relies on a bell-shaped distribution across the features with mean falling roughly in the middle.\n",
    "\n",
    "What if we only binarize the features that are well distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test a Bernoulli NB model with only well-distributed features binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes (Some features binarized + Binary features)\n",
      "F1: 0.639 \n",
      "Accuracy: 0.637\n"
     ]
    }
   ],
   "source": [
    "some_features = ['Elevation', 'Slope', 'Vertical_Distance_To_Hydrology', 'Hillshade_3pm']\n",
    "model_features = some_features + binary_features\n",
    "# model_features = some_features + binary_features[:13] + binary_features[14:]\n",
    "\n",
    "# Transform the continuous variables to binary\n",
    "bin_train_X = binarize_data(X_train, some_features) # Binarize a subset of continuous features\n",
    "bin_dev_X = binarize_data(X_dev, some_features)\n",
    "\n",
    "# Fit Bernoulli Naive Bayes\n",
    "bNB2 = BernoulliNB().fit(bin_train_X, np.array(y_train).ravel())     # Fit\n",
    "bNB_pred2 = bNB2.predict(bin_dev_X)                                  # Predict\n",
    "\n",
    "bNB_f1 = metrics.f1_score(y_dev, bNB_pred2, average = 'weighted')    # F1\n",
    "bNB_accur = bNB2.score(bin_dev_X, y_dev)                             # Accuracy\n",
    "\n",
    "print('Bernoulli Naive Bayes (Some features binarized + Binary features)')\n",
    "print(f'F1: {bNB_f1:.3f} \\nAccuracy: {bNB_accur:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform continuous features based on quantiles\n",
    "\n",
    "Binarizing the continuous features may be too simple, resulting in too much information loss. Instead, we'll take the continuous features and transform them into multinomial data based on quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantiles Chosen: [0.25, 0.5, 0.75] \n",
      "\n",
      "Thresholds for Train Data:\n",
      " [[2376. 2752. 3103.]\n",
      " [  65.  126.  261.]\n",
      " [  10.   15.   22.]\n",
      " [  67.  180.  330.]\n",
      " [   5.   32.   80.]\n",
      " [ 767. 1318. 2274.]\n",
      " [ 196.  220.  235.]\n",
      " [ 207.  223.  235.]\n",
      " [ 107.  138.  168.]\n",
      " [ 731. 1253. 1987.]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3024, 51)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Creating thresholds based on quantiles\n",
    "'''\n",
    "def define_thresholds(data, num_divisions):\n",
    "    thresholds = np.zeros([len(data.columns), num_divisions-1])\n",
    "    step = round(1/num_divisions,2)\n",
    "    prev = 0\n",
    "    bins = []\n",
    "    for i in range(num_divisions-1):\n",
    "        num = prev\n",
    "        bins.append(num+step)\n",
    "        prev = num+step\n",
    "    print(\"Quantiles Chosen:\", bins, '\\n')\n",
    "    \n",
    "    i = 0\n",
    "    for item in data.columns:\n",
    "        for j in range(len(bins)):\n",
    "            thresholds[i][j] = int(data[item].quantile(bins[j]))\n",
    "        i+=1\n",
    "    return thresholds\n",
    "\n",
    "''' \n",
    "Convert Continuous Dataframe to Multifeature Dataframe\n",
    "\n",
    "threshold:    NxM array, N = number of columns, M = number of bins\n",
    "inputs:       dataframe, threshold values\n",
    "outputs:      new dataframe\n",
    "'''\n",
    "def multifeature(data, thresholds):\n",
    "    # capture column names\n",
    "    features = list(data.columns)\n",
    "    \n",
    "    # initiate a new dataframe \n",
    "    new_df = data.copy()\n",
    "\n",
    "    i=0\n",
    "    # bin the data\n",
    "    for feature in features:\n",
    "        new_df[feature] = np.digitize(np.array(data[feature]), thresholds[i])\n",
    "        i+=1\n",
    "        \n",
    "    return new_df\n",
    "\n",
    "num_divisions = 4\n",
    "thresholds = define_thresholds(X_train[continuous_features], num_divisions)\n",
    "print(\"Thresholds for Train Data:\\n\", thresholds, '\\n')\n",
    "train_df = multifeature(X_train[continuous_features], thresholds)\n",
    "dev_df = multifeature(X_dev[continuous_features], thresholds)\n",
    "\n",
    "# This will merge our newly created multinomial features with the original binary features\n",
    "Xtrain_multi = pd.merge(train_df, X_train[binary_features], left_on='Id', right_on='Id', how='left')\n",
    "Xtrain_multi.shape\n",
    "\n",
    "Xdev_multi = pd.merge(dev_df, X_dev[binary_features], left_on='Id', right_on='Id', how='left')\n",
    "Xdev_multi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test a Multinomial NB model with Multinomial Transformation + Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes (Multinomial Transformed Features + Binary features)\n",
      "F1: 0.624 \n",
      "Accuracy: 0.623\n",
      "Confusion Matrix for Dev: \n",
      "\n",
      " [[220 116   3   0  45   1  51]\n",
      " [ 93 234   8   0  82  15   2]\n",
      " [  0   2 201  50  39 131   0]\n",
      " [  0   0  44 387   0  24   0]\n",
      " [ 65  56  24   0 266  14   0]\n",
      " [  4  12 106  25  42 239   0]\n",
      " [ 42  33   0   0  10   0 338]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=0.0001).fit(Xtrain_multi, y_train)\n",
    "pred_y_dev = model.predict(Xdev_multi)\n",
    "mNB_f1 = metrics.f1_score(y_dev, pred_y_dev, average = 'weighted')\n",
    "mNB_accur = model.score(Xdev_multi, y_dev)\n",
    "print('Bernoulli Naive Bayes (Multinomial Transformed Features + Binary features)')   \n",
    "print(f'F1: {mNB_f1:.3f} \\nAccuracy: {mNB_accur:.3f}')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_dev, pred_y_dev)\n",
    "print('Confusion Matrix for Dev: \\n\\n', cm, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Method: Voting with Gaussian NB and Bernoulli NB\n",
    "\n",
    "Neither Bernoulli or Gaussian NB did particularly well on their own, so here we test an ensemble method - which attempts to leverage both in order to increase prediction accuracy. This should allow the continuous variables to be mostly predicted by the GaussianNB, and binary variables to be mostly predicted by Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Naive Bayes (Bernoulli + Gaussian Voting)\n",
      "Accuracy: 0.580\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# binary_features.remove('Soil_Type22')\n",
    "# binary_features.remove('Soil_Type23')\n",
    "# binary_features.remove('Soil_Type29')\n",
    "# binary_features.remove('Soil_Type32')\n",
    "# binary_features.remove('Soil_Type38')\n",
    "# binary_features.remove('Soil_Type39')\n",
    "# binary_features.remove('Soil_Type40')\n",
    "clf1 = GaussianNB().fit(X_train[continuous_features], np.array(y_train).ravel())\n",
    "clf2 = BernoulliNB().fit(X_train[binary_features], np.array(y_train).ravel())\n",
    "\n",
    "eclf2 = VotingClassifier( estimators = [\n",
    "                            ('GNB', clf1) , ('BNB', clf2)], voting = 'hard')\n",
    "eclf2 = eclf2.fit(X_train, y_train)\n",
    "preds = eclf2.predict(X_dev)\n",
    "accur = eclf2.score(X_dev, y_dev)\n",
    "print(f'Ensemble Naive Bayes (Bernoulli + Gaussian Voting)\\nAccuracy: {accur:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "So far, the best model was a Bernoulli NB with \"well-distributed\" continuous variables binarized, and all binary features included.\n",
    "\n",
    "Even then, prediction accuracy and F1 still hovered right above **63%**.\n",
    "\n",
    "In an attempt to improve accuracy, we will next try to make the data better \"fit\" the model with transformations.\n",
    "\n",
    "First, we will bring some of our original EDA in to examine the distributions of continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA: Function to Plot Continuous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'text.color' : \"dimgrey\",\n",
    "                     'axes.labelcolor' : \"grey\"})\n",
    "\n",
    "# Loop through to show hist of non-binary for each \n",
    "# for d, data in enumerate(datasets):    # For each dataset\n",
    "def plot_histograms(features, data = X_train):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(features))\n",
    "    \n",
    "    for i in np.arange(0, len(features)):          # For each non-binary figure in dataset\n",
    "\n",
    "        data.iloc[:, i].plot.hist(ax = axes[i], \n",
    "                                    figsize = (50,10), \n",
    "                                    sharex = True, color = '#1c4966')\n",
    "\n",
    "        \n",
    "\n",
    "        axes[i].set_title(\"\\n\".join(wrap(features[i], 12)))\n",
    "            \n",
    "        # For All Plots\n",
    "        axes[i].set_yticks([])\n",
    "        axes[i].spines['top'].set_visible(False)\n",
    "        axes[i].spines['right'].set_visible(False)\n",
    "        axes[i].spines['left'].set_color('grey')\n",
    "        axes[i].spines['bottom'].set_color('grey')\n",
    "        axes[i].tick_params(colors = 'grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the original histograms in the EDA section, some features appear to be a bit better distributed than others, but none of them are entirely normal. Therefore, we will consider transformations for each.\n",
    "\n",
    "The Yeo-Johnson transformation is chosen as it is able to accept negative values, unlike other popular transformation algorithms like Box-cox. Following transformation, each of the variables are also (0,1) normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Function to Transform variables using SKlearn PowerTransformer\n",
    "def transform_vars(data, features, method = 'yeo-johnson', standardize = True, rename_cols = 'Y'):\n",
    "    \n",
    "    # Save indices\n",
    "    indices = data.index\n",
    "    \n",
    "    # Fit the transformer\n",
    "    pt = PowerTransformer(method = method, standardize = standardize)\n",
    "    \n",
    "    # Transform Data\n",
    "    transformed_data = pd.DataFrame(pt.fit_transform(data[features])).set_index(indices)\n",
    "    \n",
    "    # Name columns\n",
    "    if rename_cols == 'Y':\n",
    "        transformed_data.columns = [f + '_transf' for f in features]\n",
    "    else: \n",
    "        transformed_data.columns = features\n",
    "        \n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "train_X_transf = transform_vars(data = X_train, features = continuous_features, \n",
    "               method = 'yeo-johnson', standardize = True, rename_cols = 'Y')\n",
    "dev_X_transf = transform_vars(data = X_dev, features = continuous_features, \n",
    "               method = 'yeo-johnson', standardize = True, rename_cols = 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3600x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histograms(continuous_features, train_X_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following transformation each continuous feature is certainly not pefectly normally distributed, but each of them have look much more well-distributed, and it is believable that the mean would now fall roughly in the center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarize Each Transformed Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the data\n",
    "train_X_transf = binarize_data(train_X_transf, train_X_transf.columns) # Binarize all continuous features\n",
    "dev_X_transf = binarize_data(dev_X_transf, train_X_transf.columns)\n",
    "\n",
    "# Combine the new, transformed columns with original DF\n",
    "train_X_full = X_train.merge(train_X_transf, how='left', on = X_train.index)\\\n",
    "                      .set_index(X_train.index)\\\n",
    "                      .drop(['key_0'], axis = 1)\n",
    "\n",
    "dev_X_full = X_dev.merge(dev_X_transf, how='left', on = X_dev.index)\\\n",
    "                  .set_index(X_dev.index)\\\n",
    "                  .drop(['key_0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli NB with Binarized/transformed continuous features, and binary features\n",
    "\n",
    "Following transformation and binarization of the continuous features, now we can use Bernoulli Naive Bayes to model all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes (All Features transformed/binarized + Binary features)\n",
      "F1: 0.578 \n",
      "Accuracy: 0.583\n"
     ]
    }
   ],
   "source": [
    "# Transformed/binarized features + binary features\n",
    "model_features = list(train_X_transf.columns) + binary_features\n",
    "\n",
    "# Fit Bernoulli Naive Bayes\n",
    "bNB = BernoulliNB().fit(train_X_full[model_features], np.array(y_train).ravel())    # Fit\n",
    "bNB_pred = bNB.predict(dev_X_full[model_features])                                  # Predict\n",
    "\n",
    "bNB_f1 = metrics.f1_score(y_dev, bNB_pred, average = 'weighted')                    # F1\n",
    "bNB_accur = bNB.score(dev_X_full[model_features], y_dev)                            # Accuracy\n",
    "\n",
    "print('Bernoulli Naive Bayes (All Features transformed/binarized + Binary features)')\n",
    "print(f'F1: {bNB_f1:.3f} \\nAccuracy: {bNB_accur:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following transformation and binarization, our model score has decreased compared to the \"well-distributed\" binarized model.\n",
    "\n",
    "Next, will try dropping a few columns that seem to be over-predicting Cover Type 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes (All Features transformed/binarized + Binary features)\n",
      "F1: 0.519 \n",
      "Accuracy: 0.540\n"
     ]
    }
   ],
   "source": [
    "# Transformed/binarized features + binary features\n",
    "model_features = list(train_X_transf.columns) + binary_features\n",
    "model_features.remove('Soil_Type22')\n",
    "model_features.remove('Soil_Type23')\n",
    "model_features.remove('Soil_Type29')\n",
    "model_features.remove('Soil_Type32')\n",
    "model_features.remove('Soil_Type38')\n",
    "model_features.remove('Soil_Type39')\n",
    "\n",
    "# Fit Bernoulli Naive Bayes\n",
    "bNB = BernoulliNB().fit(train_X_full[model_features], np.array(y_train).ravel())    # Fit\n",
    "bNB_pred = bNB.predict(dev_X_full[model_features])                                  # Predict\n",
    "\n",
    "bNB_f1 = metrics.f1_score(y_dev, bNB_pred, average = 'weighted')                   # F1\n",
    "bNB_accur = bNB.score(dev_X_full[model_features], y_dev)                            # Accuracy\n",
    "\n",
    "print('Bernoulli Naive Bayes (All Features transformed/binarized + Binary features)')\n",
    "print(f'F1: {bNB_f1:.3f} \\nAccuracy: {bNB_accur:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since that decreased our F1 Score from 0.578 to 0.519, let's revert back to our model without the dropped soil types above and try searching for an \"ideal\" alpha value for smoothing. We will use the `GridSearchCV` function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha =  0.5783728335252256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brennagiacchino/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_features = list(train_X_transf.columns) + binary_features\n",
    "\n",
    "def GSCV(alphas):\n",
    "    model = GridSearchCV(estimator = BernoulliNB(),\n",
    "                         param_grid = alphas,\n",
    "                         cv = 5,\n",
    "                         scoring = 'accuracy',\n",
    "                         iid = False)\n",
    "    return model.fit(train_X_full[model_features], np.array(y_train).ravel())\n",
    "\n",
    "alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "nb = GSCV(alphas)\n",
    "print(\"Best alpha = \", nb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, plugging in the best alpha, test the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Grid Search to choose best parameters for Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes (All Features transformed/binarized + Binary features)\n",
      "F1: 0.578 \n",
      "Accuracy: 0.583\n"
     ]
    }
   ],
   "source": [
    "# Transformed/binarized features + binary features\n",
    "model_features = list(train_X_transf.columns) + binary_features\n",
    "\n",
    "# Fit Bernoulli Naive Bayes\n",
    "bNB = BernoulliNB(alpha = nb.best_score_).fit(train_X_full[model_features], np.array(y_train).ravel())    # Fit\n",
    "bNB_pred = bNB.predict(dev_X_full[model_features])                                  # Predict\n",
    "\n",
    "bNB_f1 = metrics.f1_score(y_dev, bNB_pred, average = 'weighted')                   # F1\n",
    "bNB_accur = bNB.score(dev_X_full[model_features], y_dev)                            # Accuracy\n",
    "\n",
    "print('Bernoulli Naive Bayes (All Features transformed/binarized + Binary features)')\n",
    "print(f'F1: {bNB_f1:.3f} \\nAccuracy: {bNB_accur:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
